{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "import torch\n",
    "from collections import defaultdict\n",
    "\n",
    "class NERPredictor:\n",
    "    def __init__(self, model_name):\n",
    "        self.model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.id2label = self.model.config.id2label\n",
    "\n",
    "    def _aggregate_tokens(self, tokens, predictions):\n",
    "        word_predictions = defaultdict(list)\n",
    "        current_word = \"\"\n",
    "        for token, pred in zip(tokens, predictions):\n",
    "            if token.startswith(\"##\"):\n",
    "                current_word += token[2:]\n",
    "            else:\n",
    "                if current_word:\n",
    "                    yield current_word, word_predictions[current_word]\n",
    "                    word_predictions[current_word] = []\n",
    "                current_word = token\n",
    "            word_predictions[current_word].append(self.id2label[pred.item()])\n",
    "        if current_word:\n",
    "            yield current_word, word_predictions[current_word]\n",
    "\n",
    "    def _get_most_common(self, labels):\n",
    "        return max(set(labels), key=labels.count)\n",
    "\n",
    "    def predict(self, text):\n",
    "        inputs = self.tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "        predictions = outputs.logits.argmax(dim=-1)[0]  # Take the first (and only) sequence\n",
    "        tokens = self.tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
    "        \n",
    "        # Filter out special tokens and their corresponding predictions\n",
    "        filtered_tokens = []\n",
    "        filtered_predictions = []\n",
    "        for token, pred in zip(tokens, predictions):\n",
    "            if token not in self.tokenizer.all_special_tokens:\n",
    "                filtered_tokens.append(token)\n",
    "                filtered_predictions.append(pred)\n",
    "        \n",
    "        return [self._get_most_common(labels) for _, labels in self._aggregate_tokens(filtered_tokens, filtered_predictions)]\n",
    "\n",
    "# Usage\n",
    "D_predictor = NERPredictor(\"ArjanvD95/by_the_horns_D42G\")\n",
    "T_predictor = NERPredictor(\"ArjanvD95/by_the_horns_T42G\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "#open jsonl file\n",
    "with open('data/by_the_horns_D/holdout.jsonl') as f:\n",
    "    data = f.readlines()\n",
    "\n",
    "#get text attribute from json file\n",
    "texts = [json.loads(d)['text'] for d in data]\n",
    "\n",
    "#do predictions on all texts, store in list\n",
    "D_lllmaaa_predictions = [D_predictor.predict(text) for text in texts]\n",
    "T_lllmaaa_predictions = [T_predictor.predict(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_llm_predictions_path = \"llm_annotations_with_D_demos.jsonl\"\n",
    "\n",
    "#open jsonl file\n",
    "with open(D_llm_predictions_path) as f:\n",
    "    D_data = f.readlines()\n",
    "\n",
    "#get tags attribute from jsonl file\n",
    "D_llm_predictions = [json.loads(d)['tags'] for d in D_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_llm_predictions_path = \"llm_annotations_with_T_demos.jsonl\"\n",
    "#open jsonl file\n",
    "with open(T_llm_predictions_path) as f:\n",
    "    T_data = f.readlines()\n",
    "\n",
    "#get tags attribute from jsonl file\n",
    "T_llm_predictions = [json.loads(d)['tags'] for d in T_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_human_path = \"data/by_the_horns_D/holdout.jsonl\"\n",
    "\n",
    "#open jsonl file\n",
    "with open(D_human_path) as f:\n",
    "    D_human = f.readlines()\n",
    "\n",
    "#get tags attribute from jsonl file\n",
    "D_hum_predictions = [json.loads(d)['tags'] for d in D_human]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_human_path = \"data/by_the_horns_T/holdout.jsonl\"\n",
    "\n",
    "#open jsonl file\n",
    "with open(T_human_path) as f:\n",
    "    T_human = f.readlines()\n",
    "\n",
    "#get tags attribute from jsonl file\n",
    "T_hum_predictions = [json.loads(d)['tags'] for d in T_human]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Method 1:\n",
      "precision_micro: 0.6049\n",
      "recall_micro: 0.5904\n",
      "f1_micro: 0.5976\n",
      "precision_macro: 0.4695\n",
      "recall_macro: 0.4690\n",
      "f1_macro: 0.4652\n",
      "accuracy: 0.9619\n",
      "\n",
      "Classification Report for Method 1:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "Collective-Literal       0.00      0.00      0.00         0\n",
      " Organisms-Literal       0.89      0.89      0.89        27\n",
      "     Parts-Literal       0.31      0.43      0.36        28\n",
      "  Products-Literal       0.68      0.56      0.61       111\n",
      "\n",
      "         micro avg       0.60      0.59      0.60       166\n",
      "         macro avg       0.47      0.47      0.47       166\n",
      "      weighted avg       0.65      0.59      0.62       166\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Plants-Products-Literal seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Animals-Products-Literal seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Animals-Organisms-Literal seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Animals-Parts-Literal seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Plants-Organisms-Literal seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Animals-Collective-Literal seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Plants-Parts-Literal seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Plants-Collective-Literal seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from seqeval.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from seqeval.metrics import classification_report\n",
    "\n",
    "def evaluate_ner(true_labels, pred_labels):\n",
    "    # Calculate metrics\n",
    "    precision_micro = precision_score(true_labels, pred_labels, average='micro')\n",
    "    recall_micro = recall_score(true_labels, pred_labels, average='micro')\n",
    "    f1_micro = f1_score(true_labels, pred_labels, average='micro')\n",
    "    \n",
    "    precision_macro = precision_score(true_labels, pred_labels, average='macro')\n",
    "    recall_macro = recall_score(true_labels, pred_labels, average='macro')\n",
    "    f1_macro = f1_score(true_labels, pred_labels, average='macro')\n",
    "    \n",
    "    accuracy = accuracy_score(true_labels, pred_labels)\n",
    "    \n",
    "    # Get detailed classification report\n",
    "    report = classification_report(true_labels, pred_labels)\n",
    "    \n",
    "    return {\n",
    "        'precision_micro': precision_micro,\n",
    "        'recall_micro': recall_micro,\n",
    "        'f1_micro': f1_micro,\n",
    "        'precision_macro': precision_macro,\n",
    "        'recall_macro': recall_macro,\n",
    "        'f1_macro': f1_macro,\n",
    "        'accuracy': accuracy,\n",
    "        'classification_report': report\n",
    "    }\n",
    "\n",
    "\n",
    "# D_lllmaaa_predictions, T_lllmaaa_predictions, D_llm_predictions, T_llm_predictions, T_hum_predictions, D_hum_predictions\n",
    "# Evaluate Method 1\n",
    "results_method1 = evaluate_ner(T_hum_predictions, T_lllmaaa_predictions)\n",
    "print(\"Results for Method 1:\")\n",
    "for metric, value in results_method1.items():\n",
    "    if metric != 'classification_report':\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "print(\"\\nClassification Report for Method 1:\")\n",
    "print(results_method1['classification_report'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from collections import Counter\n",
    "\n",
    "def calculate_metrics(y_true, y_pred, exclude_labels=None):\n",
    "    if exclude_labels is None:\n",
    "        exclude_labels = []\n",
    "    \n",
    "    # Flatten the lists\n",
    "    y_true_flat = [item for sublist in y_true for item in sublist]\n",
    "    y_pred_flat = [item for sublist in y_pred for item in sublist]\n",
    "    \n",
    "    # Get unique labels\n",
    "    labels = sorted(set(y_true_flat + y_pred_flat))\n",
    "    \n",
    "    # Calculate metrics\n",
    "    precision, recall, f1, support = precision_recall_fscore_support(y_true_flat, y_pred_flat, labels=labels, average=None)\n",
    "    \n",
    "    # Calculate micro and macro averages\n",
    "    precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(y_true_flat, y_pred_flat, labels=labels, average='micro')\n",
    "    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(y_true_flat, y_pred_flat, labels=labels, average='macro')\n",
    "    \n",
    "    # Calculate micro average without excluded labels\n",
    "    filtered_labels = [label for label in labels if label not in exclude_labels]\n",
    "    precision_micro_filtered, recall_micro_filtered, f1_micro_filtered, _ = precision_recall_fscore_support(\n",
    "        y_true_flat,\n",
    "        y_pred_flat,\n",
    "        labels=filtered_labels,\n",
    "        average='micro'\n",
    "    )\n",
    "    \n",
    "    # Create classification report\n",
    "    report = {label: {'precision': p, 'recall': r, 'f1-score': f, 'support': s} \n",
    "              for label, p, r, f, s in zip(labels, precision, recall, f1, support)}\n",
    "    \n",
    "    report['micro avg'] = {'precision': precision_micro, 'recall': recall_micro, 'f1-score': f1_micro, 'support': len(y_true_flat)}\n",
    "    report['macro avg'] = {'precision': precision_macro, 'recall': recall_macro, 'f1-score': f1_macro, 'support': len(y_true_flat)}\n",
    "    report['micro avg (filtered)'] = {'precision': precision_micro_filtered, 'recall': recall_micro_filtered, 'f1-score': f1_micro_filtered, 'support': sum(s for label, s in zip(labels, support) if label not in exclude_labels)}\n",
    "    \n",
    "    return report\n",
    "\n",
    "\n",
    "def print_f1_scores(report):\n",
    "    print(\"F1 Scores for each label:\")\n",
    "    print(\"{:<30} {:<10} {:<10}\".format(\"Label\", \"F1 Score\", \"Support\"))\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for label, metrics in report.items():\n",
    "        if label not in ['micro avg', 'macro avg', 'micro avg (filtered)']:\n",
    "            f1 = metrics['f1-score']\n",
    "            support = metrics['support']\n",
    "            print(\"{:<30} {:<10.4f} {:<10}\".format(label, f1, support))\n",
    "    \n",
    "    print(\"\\nOverall Scores:\")\n",
    "    print(\"{:<25} {:<10.4f}\".format(\"Micro F1:\", report['micro avg']['f1-score']))\n",
    "    print(\"{:<25} {:<10.4f}\".format(\"Macro F1:\", report['macro avg']['f1-score']))\n",
    "    print(\"{:<25} {:<10.4f}\".format(\"Micro F1 (without 'O'):\", report['micro avg (filtered)']['f1-score']))\n",
    "\n",
    "def evaluate_ner(true_labels, pred_labels, exclude_labels=None):\n",
    "    report = calculate_metrics(true_labels, pred_labels, exclude_labels)\n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Method 1:\n",
      "F1 Scores for each label:\n",
      "Label                          F1 Score   Support   \n",
      "--------------------------------------------------\n",
      "Animals-Collective-Literal     0.0000     0         \n",
      "Animals-Organisms-Literal      0.9057     26        \n",
      "Animals-Parts-Literal          0.3438     28        \n",
      "Animals-Products-Literal       0.5342     88        \n",
      "O                              0.9886     2640      \n",
      "Plants-Collective-Literal      0.0000     0         \n",
      "Plants-Organisms-Literal       0.0000     1         \n",
      "Plants-Parts-Literal           0.0000     0         \n",
      "Plants-Products-Literal        0.5538     27        \n",
      "\n",
      "Overall Scores:\n",
      "Micro F1:                 0.9619    \n",
      "Macro F1:                 0.3696    \n",
      "Micro F1 (without 'O'):   0.5444    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "results_method1 = calculate_metrics(T_hum_predictions, T_lllmaaa_predictions, \"O\")\n",
    "print(\"Results for Method 1:\")\n",
    "print_f1_scores(results_method1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MICRO AVG Table:\n",
      "+-----------+-------------+----------+------------+\n",
      "| Method    |   Precision |   Recall |   F1-Score |\n",
      "+===========+=============+==========+============+\n",
      "| D_LLLMaAA |      0.9648 |   0.9648 |     0.9648 |\n",
      "+-----------+-------------+----------+------------+\n",
      "| T_LLMaAA  |      0.9619 |   0.9619 |     0.9619 |\n",
      "+-----------+-------------+----------+------------+\n",
      "| D_llm     |      0.9537 |   0.9537 |     0.9537 |\n",
      "+-----------+-------------+----------+------------+\n",
      "| T_llm     |      0.9491 |   0.9491 |     0.9491 |\n",
      "+-----------+-------------+----------+------------+\n",
      "| D_hum     |      0.9851 |   0.9851 |     0.9851 |\n",
      "+-----------+-------------+----------+------------+\n",
      "| zwartbol  |      1      |   1      |     1      |\n",
      "+-----------+-------------+----------+------------+\n",
      "| kwarkbol  |      0.9648 |   0.9648 |     0.9648 |\n",
      "+-----------+-------------+----------+------------+\n",
      "\n",
      "\n",
      "\n",
      "MACRO AVG Table:\n",
      "+-----------+-------------+----------+------------+\n",
      "| Method    |   Precision |   Recall |   F1-Score |\n",
      "+===========+=============+==========+============+\n",
      "| D_LLLMaAA |      0.4491 |   0.4388 |     0.4381 |\n",
      "+-----------+-------------+----------+------------+\n",
      "| T_LLMaAA  |      0.3699 |   0.3794 |     0.3696 |\n",
      "+-----------+-------------+----------+------------+\n",
      "| D_llm     |      0.5354 |   0.4996 |     0.46   |\n",
      "+-----------+-------------+----------+------------+\n",
      "| T_llm     |      0.3598 |   0.2529 |     0.2817 |\n",
      "+-----------+-------------+----------+------------+\n",
      "| D_hum     |      0.6072 |   0.5736 |     0.5858 |\n",
      "+-----------+-------------+----------+------------+\n",
      "| zwartbol  |      1      |   1      |     1      |\n",
      "+-----------+-------------+----------+------------+\n",
      "| kwarkbol  |      0.3872 |   0.4462 |     0.3674 |\n",
      "+-----------+-------------+----------+------------+\n",
      "\n",
      "\n",
      "\n",
      "MICRO AVG (FILTERED) Table:\n",
      "+-----------+-------------+----------+------------+\n",
      "| Method    |   Precision |   Recall |   F1-Score |\n",
      "+===========+=============+==========+============+\n",
      "| D_LLLMaAA |      0.5723 |   0.5353 |     0.5532 |\n",
      "+-----------+-------------+----------+------------+\n",
      "| T_LLMaAA  |      0.5476 |   0.5412 |     0.5444 |\n",
      "+-----------+-------------+----------+------------+\n",
      "| D_llm     |      0.5859 |   0.3412 |     0.4312 |\n",
      "+-----------+-------------+----------+------------+\n",
      "| T_llm     |      0.449  |   0.2588 |     0.3284 |\n",
      "+-----------+-------------+----------+------------+\n",
      "| D_hum     |      0.8428 |   0.7882 |     0.8146 |\n",
      "+-----------+-------------+----------+------------+\n",
      "| zwartbol  |      1      |   1      |     1      |\n",
      "+-----------+-------------+----------+------------+\n",
      "| kwarkbol  |      0.5663 |   0.5529 |     0.5595 |\n",
      "+-----------+-------------+----------+------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import numpy as np\n",
    "\n",
    "def compare_ner_models(true_labels, pred_labels_list, method_names, exclude_labels=None):\n",
    "    if exclude_labels is None:\n",
    "        exclude_labels = []\n",
    "\n",
    "    results = []\n",
    "    for pred_labels in pred_labels_list:\n",
    "        report = calculate_metrics(true_labels, pred_labels, exclude_labels)\n",
    "        results.append(report)\n",
    "\n",
    "    metrics = ['micro avg', 'macro avg', 'micro avg (filtered)']\n",
    "    tables = []\n",
    "\n",
    "    for metric in metrics:\n",
    "        table_data = []\n",
    "        for i, method in enumerate(method_names):\n",
    "            row = [method]\n",
    "            row.append(f\"{results[i][metric]['precision']:.4f}\")\n",
    "            row.append(f\"{results[i][metric]['recall']:.4f}\")\n",
    "            row.append(f\"{results[i][metric]['f1-score']:.4f}\")\n",
    "            table_data.append(row)\n",
    "\n",
    "        headers = [\"Method\", \"Precision\", \"Recall\", \"F1-Score\"]\n",
    "        table = tabulate(table_data, headers=headers, tablefmt=\"grid\")\n",
    "        tables.append((metric, table))\n",
    "\n",
    "    return tables\n",
    "\n",
    "# Example usage:\n",
    "true_labels = T_hum_predictions  # Your true labels\n",
    "\n",
    "\n",
    "#\n",
    "zwartbol_path = \"zwartbol.jsonl\"\n",
    "#open jsonl file\n",
    "with open(zwartbol_path) as f:\n",
    "    zwartbol_data = f.readlines()\n",
    "\n",
    "#get tags attribute from jsonl file\n",
    "zwartbol_predictions = [json.loads(d)['tags'] for d in zwartbol_data]\n",
    "\n",
    "kwarkbol_path = \"kwarkbol.jsonl\"\n",
    "#open jsonl file\n",
    "with open(kwarkbol_path) as f:\n",
    "    kwarkbol_data = f.readlines()\n",
    "\n",
    "#get tags attribute from jsonl file\n",
    "kwarkbol_predictions = [json.loads(d)['tags'] for d in kwarkbol_data]\n",
    "\n",
    "#\n",
    "\n",
    "\n",
    "pred_labels_list = [D_lllmaaa_predictions, T_lllmaaa_predictions, D_llm_predictions, T_llm_predictions, D_hum_predictions, T_hum_predictions, zwartbol_predictions, kwarkbol_predictions]\n",
    "\n",
    "method_names = [\"D_LLLMaAA\", \"T_LLMaAA\", \"D_llm\", \"T_llm\", \"D_hum\", \"zwartbol\", \"kwarkbol\"]\n",
    "\n",
    "tables = compare_ner_models(true_labels, pred_labels_list, method_names, exclude_labels=['O'])\n",
    "\n",
    "for metric, table in tables:\n",
    "    print(f\"\\n{metric.upper()} Table:\")\n",
    "    print(table)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     File  Weighted F1 Score\n",
      "0  File_1           0.966608\n",
      "1  File_2           0.964809\n",
      "2  File_3           0.966147\n",
      "3  File_4           0.969881\n",
      "4  File_5           0.969688\n"
     ]
    }
   ],
   "source": [
    "import jsonlines\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "import os\n",
    "\n",
    "# Function to read JSONL file and extract tags\n",
    "def read_tags(file_path):\n",
    "    tags = []\n",
    "    with jsonlines.open(file_path) as reader:\n",
    "        for obj in reader:\n",
    "            tags.extend(obj['tags'])\n",
    "    return tags\n",
    "\n",
    "# Path to the folder containing the files\n",
    "folder_path = 'data/by_the_horns_T/predictions_with_demo'\n",
    "human_annotation_path = 'data/by_the_horns_D/holdout.jsonl'\n",
    "\n",
    "# Get list of files\n",
    "files = [os.path.join(folder_path, file) for file in os.listdir(folder_path) if file.endswith('.jsonl')]\n",
    "\n",
    "# Load tags from all files\n",
    "all_tags = [read_tags(file) for file in files]\n",
    "\n",
    "# Load tags from the human annotation file\n",
    "human_tags = read_tags(human_annotation_path)\n",
    "\n",
    "# Calculate weighted F1 scores\n",
    "f1_scores = {}\n",
    "for i, tags in enumerate(all_tags):\n",
    "    f1 = f1_score(human_tags, tags, average='weighted', labels=list(set(human_tags + tags)))\n",
    "    f1_scores[f'File_{i+1}'] = f1\n",
    "\n",
    "# Create a DataFrame to display the scores\n",
    "df_f1_scores = pd.DataFrame(list(f1_scores.items()), columns=['File', 'Weighted F1 Score'])\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df_f1_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MICRO AVG Matrix:\n",
      "[[0.     0.9765 0.9641 0.9658 0.9605 0.9619 0.963  0.9662]\n",
      " [0.9765 0.     0.9648 0.9641 0.9633 0.9669 0.9623 0.963 ]\n",
      " [0.9641 0.9648 0.     0.9851 0.9491 0.9537 0.9619 0.9648]\n",
      " [0.9658 0.9641 0.9851 0.     0.9541 0.958  0.9633 0.9676]\n",
      " [0.9605 0.9633 0.9491 0.9541 0.     0.9694 0.953  0.9566]\n",
      " [0.9619 0.9669 0.9537 0.958  0.9694 0.     0.9498 0.953 ]\n",
      " [0.963  0.9623 0.9619 0.9633 0.953  0.9498 0.     0.9819]\n",
      " [0.9662 0.963  0.9648 0.9676 0.9566 0.953  0.9819 0.    ]]\n",
      "\n",
      "\n",
      "\n",
      "MACRO AVG Matrix:\n",
      "[[0.     0.6514 0.3466 0.4432 0.4836 0.4467 0.5155 0.4395]\n",
      " [0.6514 0.     0.3674 0.482  0.4788 0.5244 0.4106 0.4041]\n",
      " [0.3466 0.3674 0.     0.5858 0.2817 0.46   0.3696 0.4381]\n",
      " [0.4432 0.482  0.5858 0.     0.3534 0.4831 0.4642 0.5273]\n",
      " [0.4836 0.4788 0.2817 0.3534 0.     0.4999 0.374  0.3516]\n",
      " [0.4467 0.5244 0.46   0.4831 0.4999 0.     0.3636 0.3828]\n",
      " [0.5155 0.4106 0.3696 0.4642 0.374  0.3636 0.     0.6236]\n",
      " [0.4395 0.4041 0.4381 0.5273 0.3516 0.3828 0.6236 0.    ]]\n",
      "\n",
      "\n",
      "\n",
      "MICRO AVG (FILTERED) Matrix:\n",
      "[[0.     0.7356 0.5586 0.5714 0.5364 0.5573 0.6103 0.6273]\n",
      " [0.7356 0.     0.5595 0.5477 0.5455 0.6113 0.5689 0.5723]\n",
      " [0.5586 0.5595 0.     0.8146 0.3284 0.4312 0.5444 0.5532]\n",
      " [0.5714 0.5477 0.8146 0.     0.3813 0.4651 0.5749 0.5912]\n",
      " [0.5364 0.5455 0.3284 0.3813 0.     0.5279 0.4361 0.4591]\n",
      " [0.5573 0.6113 0.4312 0.4651 0.5279 0.     0.397  0.4109]\n",
      " [0.6103 0.5689 0.5444 0.5749 0.4361 0.397  0.     0.7951]\n",
      " [0.6273 0.5723 0.5532 0.5912 0.4591 0.4109 0.7951 0.    ]]\n",
      "\n",
      "\n",
      "Results have been saved to 'pegel.csv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/arjan_v_d/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "def pairwise_ner_comparison(pred_labels_list, method_names, exclude_labels=None):\n",
    "    if exclude_labels is None:\n",
    "        exclude_labels = [] \n",
    "\n",
    "    n_methods = len(pred_labels_list)\n",
    "    metrics = ['micro avg', 'macro avg', 'micro avg (filtered)']\n",
    "    results = {metric: np.zeros((n_methods, n_methods)) for metric in metrics}\n",
    "\n",
    "    for i in range(n_methods):\n",
    "        for j in range(n_methods):\n",
    "            if i != j:\n",
    "                report = calculate_metrics(pred_labels_list[i], pred_labels_list[j], exclude_labels)\n",
    "                for metric in metrics:\n",
    "                    results[metric][i, j] = report[metric]['f1-score']\n",
    "\n",
    "    # Create CSV file\n",
    "    with open('pegel.csv', 'w', newline='') as csvfile: #!!!\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(['Metric'] + method_names)\n",
    "\n",
    "        for metric in metrics:\n",
    "            writer.writerow([f\"\\n{metric.upper()}\"])\n",
    "            for i, method in enumerate(method_names):\n",
    "                row = [method] + [f\"{score:.4f}\" for score in results[metric][i]]\n",
    "                writer.writerow(row)\n",
    "\n",
    "    return results\n",
    "\n",
    "# Example usage:\n",
    "pred_labels_list = [D_lllmaaa_predictions, T_lllmaaa_predictions, D_llm_predictions, T_llm_predictions, D_hum_predictions, T_hum_predictions,zwartbol_predictions, kwarkbol_predictions]\n",
    "pred_labels_list.reverse()\n",
    "method_names = [\"D_LLLMaAA\", \"T_LLMaAA\", \"D_llm\", \"T_llm\", \"D_hum\", \"T_hum\", \"zwartbol\", \"kwarkbol\"]\n",
    "method_names.reverse()\n",
    "results = pairwise_ner_comparison(pred_labels_list, method_names, exclude_labels=['O'])\n",
    "\n",
    "# Print matrices (optional)\n",
    "for metric, matrix in results.items():\n",
    "    print(f\"\\n{metric.upper()} Matrix:\")\n",
    "    print(np.array2string(matrix, precision=4, suppress_small=True))\n",
    "    print(\"\\n\")\n",
    "\n",
    "print(\"Results have been saved to 'pegel.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Error Analyis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "import torch\n",
    "from collections import defaultdict\n",
    "\n",
    "class NERPredictor:\n",
    "    def __init__(self, model_name):\n",
    "        self.model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.id2label = self.model.config.id2label\n",
    "\n",
    "    def _aggregate_tokens(self, tokens, predictions):\n",
    "        word_predictions = defaultdict(list)\n",
    "        current_word = \"\"\n",
    "        current_start = 0\n",
    "        for token, pred in zip(tokens, predictions):\n",
    "            if token.startswith(\"##\"):\n",
    "                current_word += token[2:]\n",
    "            else:\n",
    "                if current_word:\n",
    "                    yield current_word, word_predictions[current_word], current_start\n",
    "                    word_predictions[current_word] = []\n",
    "                    current_start += len(current_word) + 1  # +1 for space\n",
    "                current_word = token\n",
    "            word_predictions[current_word].append(self.id2label[pred.item()])\n",
    "        if current_word:\n",
    "            yield current_word, word_predictions[current_word], current_start\n",
    "\n",
    "    def _get_most_common(self, labels):\n",
    "        return max(set(labels), key=labels.count)\n",
    "\n",
    "    def predict(self, text):\n",
    "        inputs = self.tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "        predictions = outputs.logits.argmax(dim=-1)[0]  # Take the first (and only) sequence\n",
    "        tokens = self.tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
    "        \n",
    "        # Filter out special tokens and their corresponding predictions\n",
    "        filtered_tokens = []\n",
    "        filtered_predictions = []\n",
    "        for token, pred in zip(tokens, predictions):\n",
    "            if token not in self.tokenizer.all_special_tokens:\n",
    "                filtered_tokens.append(token)\n",
    "                filtered_predictions.append(pred)\n",
    "        \n",
    "        results = []\n",
    "        for word, labels, start in self._aggregate_tokens(filtered_tokens, filtered_predictions):\n",
    "            most_common_label = self._get_most_common(labels)\n",
    "            if most_common_label != \"O\":  # Assuming \"O\" is used for non-entity tokens\n",
    "                results.append({\n",
    "                    \"entity\": word,\n",
    "                    \"label\": most_common_label,\n",
    "                    \"start\": start,\n",
    "                    \"end\": start + len(word)\n",
    "                })\n",
    "        return results\n",
    "\n",
    "# Usage\n",
    "D_predictor = NERPredictor(\"ArjanvD95/by_the_horns_D42G\")\n",
    "T_predictor = NERPredictor(\"ArjanvD95/by_the_horns_T42G\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [json.loads(d)['tokens'] for d in D_data]\n",
    "texts = [json.loads(d)['text'] for d in D_data]\n",
    "\n",
    "D_hum_path = \"data/by_the_horns_D/holdout.jsonl\"\n",
    "T_hum_path = \"data/by_the_horns_T/holdout.jsonl\"\n",
    "\n",
    "#open jsonl file\n",
    "with open(D_hum_path) as f:\n",
    "    D_data = f.readlines()\n",
    "\n",
    "with open(T_hum_path) as f:\n",
    "    T_data = f.readlines()\n",
    "\n",
    "\n",
    "#get tags attribute from jsonl file\n",
    "D_llm_predictions = [json.loads(d)['tags'] for d in D_data]\n",
    "\n",
    "with open('llm_annotations_with_D_demos.jsonl') as f:\n",
    "    direct_D_data = f.readlines()\n",
    "    \n",
    "with open('llm_annotations_with_T_demos.jsonl') as f:\n",
    "    direct_T_data = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_D = [json.loads(d)['labels'] for d in D_data]\n",
    "labels_T = [json.loads(d)['labels'] for d in T_data]\n",
    "labels_direct_D = [json.loads(d)['labels'] for d in direct_D_data]\n",
    "labels_direct_T = [json.loads(d)['labels'] for d in direct_T_data]\n",
    "labels_indirect_D = [[{'span': item['entity'], 'type': item['label']} for item in entry] for entry in [D_predictor.predict(text) for text in texts]]\n",
    "labels_indirect_T = [[{'span': item['entity'], 'type': item['label']} for item in entry] for entry in [T_predictor.predict(text) for text in texts]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all the annotations into a list of dictionaries\n",
    "combined_annotations = []\n",
    "for i in range(len(texts)):\n",
    "    combined_annotations.append({\n",
    "        'text': texts[i],\n",
    "        'labels_D': labels_D[i],\n",
    "        'labels_T': labels_T[i],\n",
    "        'labels_direct_D': labels_direct_D[i],\n",
    "        'labels_direct_T': labels_direct_T[i],\n",
    "        'labels_indirect_D': labels_indirect_D[i],\n",
    "        'labels_indirect_T': labels_indirect_T[i]\n",
    "    })\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(combined_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"error_analysis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "import torch\n",
    "from collections import defaultdict\n",
    "\n",
    "class NERPredictor:\n",
    "    def __init__(self, model_name):\n",
    "        self.model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.id2label = self.model.config.id2label\n",
    "\n",
    "    def _aggregate_tokens(self, tokens, predictions):\n",
    "        word_predictions = defaultdict(list)\n",
    "        current_word = \"\"\n",
    "        current_start = 0\n",
    "        for token, pred in zip(tokens, predictions):\n",
    "            if token.startswith(\"##\"):\n",
    "                current_word += token[2:]\n",
    "            else:\n",
    "                if current_word:\n",
    "                    yield current_word, word_predictions[current_word], current_start\n",
    "                    word_predictions[current_word] = []\n",
    "                    current_start += len(current_word) + 1  # +1 for space\n",
    "                current_word = token\n",
    "            word_predictions[current_word].append(self.id2label[pred.item()])\n",
    "        if current_word:\n",
    "            yield current_word, word_predictions[current_word], current_start\n",
    "\n",
    "    def _get_most_common(self, labels):\n",
    "        return max(set(labels), key=labels.count)\n",
    "\n",
    "    def predict(self, text):\n",
    "        inputs = self.tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "        predictions = outputs.logits.argmax(dim=-1)[0]  # Take the first (and only) sequence\n",
    "        tokens = self.tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
    "        \n",
    "        # Filter out special tokens and their corresponding predictions\n",
    "        filtered_tokens = []\n",
    "        filtered_predictions = []\n",
    "        for token, pred in zip(tokens, predictions):\n",
    "            if token not in self.tokenizer.all_special_tokens:\n",
    "                filtered_tokens.append(token)\n",
    "                filtered_predictions.append(pred)\n",
    "        \n",
    "        results = []\n",
    "        for word, labels, start in self._aggregate_tokens(filtered_tokens, filtered_predictions):\n",
    "            most_common_label = self._get_most_common(labels)\n",
    "            if most_common_label != \"O\":  # Assuming \"O\" is used for non-entity tokens\n",
    "                results.append({\n",
    "                    \"entity\": word,\n",
    "                    \"label\": most_common_label,\n",
    "                    \"start\": start,\n",
    "                    \"end\": start + len(word)\n",
    "                })\n",
    "        return results\n",
    "\n",
    "# Usage\n",
    "D_predictor = NERPredictor(\"ArjanvD95/by_the_horns_D42G\")\n",
    "T_predictor = NERPredictor(\"ArjanvD95/by_the_horns_T42G\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tools give the same annotation 2 times.\n"
     ]
    }
   ],
   "source": [
    "def all_tools_same(row):\n",
    "    annotations = [\n",
    "        row['labels_D'], \n",
    "        row['labels_T'], \n",
    "        row['labels_direct_D'], \n",
    "        row['labels_direct_T'], \n",
    "        row['labels_indirect_D'], \n",
    "        row['labels_indirect_T']\n",
    "    ]\n",
    "    \n",
    "    # Flatten the list of annotations and convert to a set of tuples\n",
    "    annotations_flat = [tuple(item.items()) for sublist in annotations for item in sublist]\n",
    "    \n",
    "    # Check if all flattened annotations are the same\n",
    "    return len(set(annotations_flat)) == 1\n",
    "\n",
    "# Apply the function to each row\n",
    "df['all_tools_same'] = df.apply(all_tools_same, axis=1)\n",
    "\n",
    "# Count how often all tools give the same annotation\n",
    "same_annotation_count = df['all_tools_same'].sum()\n",
    "\n",
    "print(f\"All tools give the same annotation {same_annotation_count} times.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to annotation_comparison_results.txt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Assuming you have your DataFrame `df`\n",
    "# df = pd.DataFrame({...})\n",
    "\n",
    "# Prepare the text content\n",
    "text_content = \"\"\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    text_content += f\"For sentence {index+1}:\\n\"\n",
    "    text_content += f\"Text: {row['text']}\\n\"\n",
    "    text_content += \"labels_D has: \" + json.dumps(row['labels_D'], indent=4) + \"\\n\"\n",
    "    text_content += \"labels_T has: \" + json.dumps(row['labels_T'], indent=4) + \"\\n\"\n",
    "    text_content += \"labels_direct_D has: \" + json.dumps(row['labels_direct_D'], indent=4) + \"\\n\"\n",
    "    text_content += \"labels_direct_T has: \" + json.dumps(row['labels_direct_T'], indent=4) + \"\\n\"\n",
    "    text_content += \"labels_indirect_D has: \" + json.dumps(row['labels_indirect_D'], indent=4) + \"\\n\"\n",
    "    text_content += \"labels_indirect_T has: \" + json.dumps(row['labels_indirect_T'], indent=4) + \"\\n\"\n",
    "    text_content += \"\\n\"\n",
    "\n",
    "# Save the results to a text file\n",
    "with open('annotation_comparison_results.txt', 'w') as file:\n",
    "    file.write(text_content)\n",
    "\n",
    "print(\"Results saved to annotation_comparison_results.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src/confusion_matrices.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python src/ner_confusion_matrices.py --d_human_annotations annotations/parsed_annotations/annotations_D.json  --t_human_annotations annotations/parsed_annotations/annotation_T.json --direct_demo1 data/by_the_horns_D/predictions_with_demo --direct_demo2 data/by_the_horns_T/predictions_with_T --output_folder "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
