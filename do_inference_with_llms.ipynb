{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Run inference with LLMs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_annotate_path = \"data/by_the_horns_D/holdout.jsonl\"\n",
    "demo_path = \"data/by_the_horns_D/holdout-knn-demo.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's analyze the text step by step to identify any plant or animal-related entities and annotate them accordingly.\n",
      "\n",
      "1. \"Doch in kommerlyke tyden word dit kruid, een weinig geroost, door de menschen ten spyze gebruikt.\"\n",
      "\n",
      "- \"kruid\": This is a Dutch word for \"herb.\" \n",
      "  - Category: Plant (it's a plant that usually stays in one place and creates its own food using sunlight, water, and air).\n",
      "  - Type: Organisms (refers to a whole, living plant).\n",
      "  - Usage: Literal (it directly refers to the herb as it is used by humans).\n",
      "\n",
      "Therefore, the annotation for this text would be:\n",
      "\n",
      "```json\n",
      "[{\"span\": \"kruid\", \"type\": \"Plant-Organisms-Literal\"}]\n",
      "```\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import ujson as json\n",
    "import os\n",
    "import re\n",
    "import asyncio\n",
    "from func_timeout import func_set_timeout\n",
    "from openai import RateLimitError\n",
    "from langchain_core import prompts, output_parsers\n",
    "from langchain_openai import ChatOpenAI\n",
    "from aiolimiter import AsyncLimiter\n",
    "\n",
    "\n",
    "\n",
    "class Annotator:\n",
    "    def __init__(self, engine: str = 'gpt-3.5-turbo', config_path: str = 'default', dataset: str = None):\n",
    "        config_path = config_path\n",
    "        with open(config_path, 'r', encoding='utf-8') as file:\n",
    "            config = json.load(file)\n",
    "\n",
    "        self.demo_file = {}  # Assuming you load this from somewhere\n",
    "        self.demo_index = {}  # Assuming you load this from somewhere\n",
    "\n",
    "        self.dataset = dataset or config['dataset']\n",
    "        self.task = config['task']\n",
    "        self.description = config['description']\n",
    "        self.guidance = config['guidance']\n",
    "        self.input_format = config['input_format']\n",
    "        self.output_format = config['output_format']\n",
    "        self.struct_format = config['struct_format']\n",
    "\n",
    "        self.llm = ChatOpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"), model=engine)\n",
    "\n",
    "        # Setup prompt and output parsers\n",
    "\n",
    "        self.prompt_template = prompts.ChatPromptTemplate.from_messages([\n",
    "            (\"system\", self.description.replace(\"{\", \"{{\").replace(\"}\", \"}}\")),  # Escaping the braces\n",
    "            (\"system\", self.guidance),\n",
    "            (\"user\", \"{input}\")\n",
    "        ])\n",
    "\n",
    "        self.output_parser = output_parsers.StrOutputParser()\n",
    "        self.chain = self.prompt_template | self.llm | self.output_parser\n",
    "\n",
    "        # Setup for enrichment strategy\n",
    "        self.enrichment_description = config[\"enrichment_description\"] #must put in config\n",
    "        self.enrichment_llm = ChatOpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"), model=\"gpt-3.5-turbo-0125\")\n",
    "        self.enrichment_prompt_template = prompts.ChatPromptTemplate.from_messages([\n",
    "            (\"system\", self.enrichment_description), \n",
    "            (\"user\", \"{input}\")\n",
    "        ])\n",
    "        self.enrichment_output_parser = output_parsers.StrOutputParser()\n",
    "        self.enrichment_chain = self.enrichment_prompt_template | self.enrichment_llm | self.enrichment_output_parser\n",
    "        self.limiter = AsyncLimiter(1000)\n",
    "\n",
    "    def prepare_demo(self, sample_id):\n",
    "        # This method prepares the demo data for a given sample\n",
    "        if sample_id in self.demo_index:\n",
    "            return [self.demo_file[pointer['id']] for pointer in reversed(self.demo_index[sample_id])]\n",
    "        else:\n",
    "            return []  # or handle the case where there's no demo data for the sample\n",
    "\n",
    "    def generate_prompt(self, sample, demo=None):\n",
    "        to_annotate = self.input_format.format(json.dumps(sample['text']))\n",
    "        if demo:\n",
    "            demo_annotations = \"\\n\".join(\n",
    "                f\"{self.input_format.format(json.dumps(d['text']))}\\n{self.output_format.format(json.dumps(d['labels']))}\" for d in demo\n",
    "            )\n",
    "            return f\"Here are some examples:\\n{demo_annotations}\\n\\nPlease now annotate the following input:\\n{to_annotate}\"\n",
    "        else:\n",
    "            return f\"Please annotate the following input:\\n{to_annotate}\"\n",
    "    \n",
    "    @func_set_timeout(60)\n",
    "    def online_annotate(self, sample, demo=None):\n",
    "        demo = self.prepare_demo(sample['id'])\n",
    "        annotation_prompt = self.generate_prompt(sample, demo)\n",
    "        retry_count = 0  # Initialize retry counter\n",
    "\n",
    "        while retry_count < 3:  # Allow up to 3 attempts (initial + 2 retries)\n",
    "            try:\n",
    "                response = self.chain.invoke({\"input\": annotation_prompt})\n",
    "                print(response)\n",
    "                return self.postprocess(response) #samesies\n",
    "\n",
    "            except RateLimitError:\n",
    "                print(\"Rate limit exceeded. Please wait and try again.\")\n",
    "                print(f\"Problem was with: {annotation_prompt}\")\n",
    "                return None\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error during annotation: {e}\")\n",
    "                print(f\"Problem was with: {annotation_prompt}\")\n",
    "                retry_count += 1  # Increment retry counter\n",
    "\n",
    "                if retry_count == 3:\n",
    "                    print(\"Max retries reached. Aborting operation.\")\n",
    "                    return None\n",
    "\n",
    "                print(\"Retrying...\")\n",
    "\n",
    "        return None\n",
    "    \n",
    "    def postprocess(self, result):\n",
    "        meta_path = \"data/by_the_horns_D/meta.json\"\n",
    "        with open(meta_path, 'r') as file:\n",
    "            meta = json.load(file)\n",
    "        tagset = meta['tagset']\n",
    "        list_pattern = r\"\\[([^\\]]*)\\]\"\n",
    "        match = re.search(list_pattern, result)\n",
    "        if match:\n",
    "            # Convert the matched string into a list if it is not empty, otherwise create an empty list\n",
    "            extracted_result = eval(f\"[{match.group(1)}]\") if match.group(1) else []\n",
    "        else:\n",
    "            print(\"No list found.\")\n",
    "\n",
    "        outputs = []\n",
    "        for entity in extracted_result:\n",
    "            if not isinstance(entity, dict):\n",
    "                continue\n",
    "            if 'type' not in entity or 'span' not in entity:\n",
    "                continue\n",
    "            if entity['type'] in tagset:\n",
    "                outputs.append(entity)\n",
    "        return outputs\n",
    "\n",
    "annotator = Annotator(engine='gpt-4o', config_path= 'src/llm_annotator/configs/by_the_horns_D_base.json')\n",
    "sample = {\"tokens\": [\"Doch\", \"in\", \"kommerlyke\", \"tyden\", \"word\", \"dit\", \"kruid\", \",\", \"een\", \"weinig\", \"geroost\", \",\", \"door\", \"de\", \"menschen\", \"ten\", \"spyze\", \"gebruikt\", \".\"], \"tags\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"Plants-Products-Literal\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"], \"text\": \"Doch in kommerlyke tyden word dit kruid, een weinig geroost, door de menschen ten spyze gebruikt.\", \"labels\": [{\"span\": \"kruid\", \"type\": \"Plants-Products-Literal\"}], \"id\": \"137\"}\n",
    "print(annotator.online_annotate(sample))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
